{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caltech Machine Learning Homework # 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Perceptron\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "from itertools import product\n",
    "import scipy.special\n",
    "from scipy import optimize\n",
    "import scipy.optimize as spo\n",
    "from sympy import Symbol, Derivative\n",
    "\n",
    "def dbg():\n",
    "    import pdb; pdb.set_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: https://work.caltech.edu/homework/hw6.pdf\n",
    "\n",
    "Answers: http://work.caltech.edu/homework/hw6_sol.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting and Deterministic Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/overfitting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[b]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization with Weight Decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/regdecay1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_IN is 0.02857142857142857\n",
      "E_OUT is 0.084\n"
     ]
    }
   ],
   "source": [
    "train = np.loadtxt('data/hw5/in.dta.txt')\n",
    "test = np.loadtxt('data/hw5/out.dta.txt')\n",
    "\n",
    "X_train = train[:,:-1]\n",
    "Y_train = train[:,2]\n",
    "N_train = X_train[:, 0].size\n",
    "\n",
    "X_test = test[:,:-1]\n",
    "Y_test = test[:,2]\n",
    "N_test = X_test[:, 0].size\n",
    "\n",
    "def theta(X):\n",
    "    assert(X.shape == (2,))\n",
    "    x1, x2 = X\n",
    "    return np.array([1, x1, x2, x1 * x1, x2 * x2, x1 * x2, np.abs(x1-x2), np.abs(x1+x2)])\n",
    "\n",
    "# Non-linear Transformation\n",
    "Z_train = np.apply_along_axis(theta, 1, X_train)\n",
    "Z_test = np.apply_along_axis(theta, 1, X_test)\n",
    "\n",
    "# Linear Regression\n",
    "X_dagger = np.dot(np.linalg.inv(np.dot(Z_train.T, Z_train)), Z_train.T)\n",
    "W = np.dot(X_dagger, Y_train)\n",
    "\n",
    "# In-sample Error\n",
    "preds_train = np.sign(np.dot(Z_train, W))\n",
    "E_IN = sum(preds_train != Y_train) / N_train\n",
    "\n",
    "# Out-of-sample Error\n",
    "preds_test = np.sign(np.dot(Z_test, W))\n",
    "E_OUT = sum(preds_test != Y_test) / N_test\n",
    "\n",
    "print(f\"E_IN is {E_IN}\")\n",
    "print(f\"E_OUT is {E_OUT}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[a]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/regdecay2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_IN_REG is 0.02857142857142857\n",
      "E_OUT_REG is 0.08\n"
     ]
    }
   ],
   "source": [
    "k = -3\n",
    "lambd = 10 ** k\n",
    "\n",
    "# Linear Regression with Regularization\n",
    "X_dagger_reg = np.dot(np.linalg.inv(np.dot(Z_train.T, Z_train) + lambd * np.identity(W.size) ), Z_train.T)\n",
    "W_reg = np.dot(X_dagger_reg, Y_train)\n",
    "\n",
    "# In-sample Error\n",
    "preds_train_reg = np.sign(np.dot(Z_train, W_reg))\n",
    "E_IN_REG = sum(preds_train_reg != Y_train) / N_train\n",
    "\n",
    "# Out-of-sample Error\n",
    "preds_test_reg = np.sign(np.dot(Z_test, W_reg))\n",
    "E_OUT_REG = sum(preds_test_reg != Y_test) / N_test\n",
    "\n",
    "print(f\"E_IN_REG is {E_IN_REG}\")\n",
    "print(f\"E_OUT_REG is {E_OUT_REG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much happening here with that small a level of k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[d]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/regdecay3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_IN_REG is 0.37142857142857144\n",
      "E_OUT_REG is 0.436\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "lambd = 10 ** k\n",
    "\n",
    "# Linear Regression with Regularization\n",
    "X_dagger_reg = np.dot(np.linalg.inv(np.dot(Z_train.T, Z_train) + lambd * np.identity(W.size) ), Z_train.T)\n",
    "W_reg = np.dot(X_dagger_reg, Y_train)\n",
    "\n",
    "# In-sample Error\n",
    "preds_train_reg = np.sign(np.dot(Z_train, W_reg))\n",
    "E_IN_REG = sum(preds_train_reg != Y_train) / N_train\n",
    "\n",
    "# Out-of-sample Error\n",
    "preds_test_reg = np.sign(np.dot(Z_test, W_reg))\n",
    "E_OUT_REG = sum(preds_test_reg != Y_test) / N_test\n",
    "\n",
    "print(f\"E_IN_REG is {E_IN_REG}\")\n",
    "print(f\"E_OUT_REG is {E_OUT_REG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[e]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/regdecay4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.084, 0.056, 0.092, 0.124, 0.228]\n"
     ]
    }
   ],
   "source": [
    "def run_with_k(k):\n",
    "    lambd = 10 ** k\n",
    "    \n",
    "    # Linear Regression with Regularization\n",
    "    X_dagger_reg = np.dot(np.linalg.inv(np.dot(Z_train.T, Z_train) + lambd * np.identity(W.size) ), Z_train.T)\n",
    "    W_reg = np.dot(X_dagger_reg, Y_train)\n",
    "\n",
    "    # In-sample Error\n",
    "    preds_train_reg = np.sign(np.dot(Z_train, W_reg))\n",
    "    E_IN = sum(preds_train_reg != Y_train) / N_train\n",
    "\n",
    "    # Out-of-sample Error\n",
    "    preds_test_reg = np.sign(np.dot(Z_test, W_reg))\n",
    "    E_OUT = sum(preds_test_reg != Y_test) / N_test\n",
    "    \n",
    "    return E_OUT\n",
    "\n",
    "print([run_with_k(k)for k in range(-2,3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smallest `E_OUT` is $0.056$ at index `1`, so the answer is $k = -1$ **[d]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/regdecay5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that $k=3$ is over-regularizing, and $k=-3$ is under-regularizing, so we can limit ourselves to the integer values between $-3$ and $3$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08, 0.084, 0.056, 0.092, 0.124, 0.228, 0.436]\n"
     ]
    }
   ],
   "source": [
    "print([run_with_k(k)for k in range(-3,4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the smallest E_OUT is indeed achieved at $k=-1$, and it's closest to answer **[b]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/regpoly.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have:\n",
    "\n",
    "$$\n",
    "H(Q, C, Q_{0}) = {h | h(x) = \\textbf w^{T} \\textbf z \\in H_{Q};w_{q} = C for \\  q \\geqslant Q_{0}}\n",
    "$$\n",
    "\n",
    "**Expanding [a]:**\n",
    "$$\n",
    "H(10, 0, 3) = {h | h(x) = \\textbf w^{T} \\textbf z \\in H_{10};w_{q} = 0 for \\  q \\geqslant 3}\n",
    "$$\n",
    "\n",
    "$$\n",
    "H(10, 0, 4) = {h | h(x) = \\textbf w^{T} \\textbf z \\in H_{10};w_{q} = 0 for \\  q \\geqslant 4}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be essentially a third order polynomial, since all terms $geqslant 4$ will go to zero under the constraint.\n",
    "\n",
    "\n",
    "Hence [a] is incorrect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expanding [b]:**\n",
    "$$\n",
    "H(10, 1, 3) = {h | h(x) = \\textbf w^{T} \\textbf z \\in H_{10};w_{q} = 1 for \\  q \\geqslant 3}\n",
    "$$\n",
    "\n",
    "$$\n",
    "H(10, 1, 4) = {h | h(x) = \\textbf w^{T} \\textbf z \\in H_{10};w_{q} = 1 for \\  q \\geqslant 4}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no effective constraint here at all, so the union of the two should be effectively $\\textbf H_{10}$.\n",
    "\n",
    "Hence [b] is incorrect as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expanding [c]:**\n",
    "[c] is the same expansion as [a] above.\n",
    "\n",
    "So this is the intersection of a third-order with a second-order polynomial, which yields a second-order polynomial\n",
    "\n",
    "Hence **[c]** looks correct!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Let's double-check by looking at [d]:\n",
    "\n",
    "The two Hypothesis sets here look again effectively unconstrained as in [b], so their intersection should be $\\textbf H_{10}$ and not $\\textbf H_{1}$\n",
    "\n",
    "Confirming that **[c]** looks like the correct answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/neuralnets1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Lecture 10:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/neuralnets2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, $d$ seems to be the dimensionality or number of inputs in the layer, so our network should look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/neuralnets3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, also from Lecture 10:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/neuralnets4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/neuralnets5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So including the non-update to $x_{0}^{l-1}$ we get 44 operations, answer **[d]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/neuralnets5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum should be achieved if we arrange all hidden layers as single neuron layers (with $d=1$).\n",
    "\n",
    "![](imgs/neuralnets6.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I believe it should be **[a]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/neuralnets6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make the first hidden layer as large as possible:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/neuralnets7.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks promising, but can we go larger?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/neuralnets8.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general formula should something like this:\n",
    "    \n",
    "$$\n",
    "maximize ((\\sum_{h=1}^H d_{h-1\\ n_H}(d_{h\\ n_H}-1)) + d_{H\\ n_H})\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$d_{0\\ n_H}=10$ for any $n_H$\n",
    "\n",
    "$1 \\leq H \\leq \\frac{36}{2}=18 $\n",
    "\n",
    "$2 \\leq n_H \\leq 36$ (for each $H$) \n",
    "\n",
    "$\\sum_{h=1}^H d_{h} = 36$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore that =)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find all the possible different architectures, [this](https://en.wikipedia.org/wiki/Composition_(combinatorics)) helped greatly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So knowing that the term for this is a \"composition\", I stole the following useful recursive algorithm from [here](https://www.geeksforgeeks.org/print-all-combinations-of-points-that-can-compose-a-given-number/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9227465 valid \"architectures\" of 36 neurons arranged in layers of at least 2!\n"
     ]
    }
   ],
   "source": [
    "architectures = [] # Will hold all possible architectures\n",
    "N = 36 # Number of neurons to distribute amongst hidden layers\n",
    "MIN_LAYER_SIZE = 2 # Minimum size of a layer (important for composition calculation)\n",
    "d_0 = 10 # Dimension of input layer\n",
    "\n",
    "def computeCompositionsRecursively(n, i, arr = [0] * N):\n",
    "    if (n==0):\n",
    "        architectures.append([d_0] + arr.copy()[:i])\n",
    "    elif(n > 0):\n",
    "        for k in range(MIN_LAYER_SIZE, N+1):\n",
    "            arr[i] = k\n",
    "            computeCompositionsRecursively(n - k, i + 1, arr)\n",
    "            \n",
    "computeCompositionsRecursively(N, 0)\n",
    "\n",
    "print(f\"Found {len(architectures)} valid \\\"architectures\\\" of {N} neurons arranged in layers of at least 2!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now find the maximum according to the \"general formula\" above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum weights achievable: 510\n"
     ]
    }
   ],
   "source": [
    "maxWeights = 0\n",
    "# archs = [[2, 2, 4], [2, 3, 4], [2, 4, 4]]\n",
    "\n",
    "for a in architectures:\n",
    "    weights = 0\n",
    "    \n",
    "    for i in range(1, len(a)):\n",
    "        d_hminus1 = a[i-1]\n",
    "        d_h = a[i]\n",
    "        weights += d_hminus1 * (d_h - 1)\n",
    "        \n",
    "    d_H = a[-1]\n",
    "    weights += d_H\n",
    "    \n",
    "    maxWeights = max(weights, maxWeights)\n",
    "    \n",
    "print(f\"Maximum weights achievable: {maxWeights}\")\n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the answer is actually **[e]** =)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 - python",
   "language": "python",
   "name": "ipython_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
