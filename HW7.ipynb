{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caltech Machine Learning Homework # 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Perceptron\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "from itertools import product\n",
    "import scipy.special\n",
    "from scipy import optimize\n",
    "import scipy.optimize as spo\n",
    "from sympy import Symbol, Derivative\n",
    "import functools\n",
    "from sklearn import svm\n",
    "\n",
    "def dbg():\n",
    "    import pdb; pdb.set_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: https://work.caltech.edu/homework/hw7.pdf\n",
    "\n",
    "Answers: http://work.caltech.edu/homework/hw7_sol.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/val1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_VAL for k=3 is 0.3\n",
      "E_VAL for k=4 is 0.5\n",
      "E_VAL for k=5 is 0.2\n",
      "E_VAL for k=6 is 0.0\n",
      "E_VAL for k=7 is 0.1\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt('data/hw7/in.dta.txt')\n",
    "\n",
    "N_train = 25\n",
    "X_train = data[:N_train,:-1]\n",
    "Y_train = data[:N_train,2]\n",
    "\n",
    "N_val = 10\n",
    "X_val = data[-N_val:,:-1]\n",
    "Y_val = data[-N_val:,2]\n",
    "\n",
    "def phi(X, k):\n",
    "    assert(X.shape == (2,))\n",
    "    x1, x2 = X\n",
    "    return np.array([1, x1, x2, x1 * x1, x2 * x2, x1 * x2, np.abs(x1-x2), np.abs(x1+x2)])[:k+1]\n",
    "\n",
    "for k in range(3, 8):\n",
    "    # Non-Linear Transformation\n",
    "    Z_train = np.apply_along_axis(phi, 1, X_train, k)\n",
    "    Z_val = np.apply_along_axis(phi, 1, X_val, k)\n",
    "\n",
    "    # Linear Regression\n",
    "    X_dagger = np.dot(np.linalg.inv(np.dot(Z_train.T, Z_train)), Z_train.T)\n",
    "    W = np.dot(X_dagger, Y_train)\n",
    "\n",
    "    # Validation Error\n",
    "    preds_val = np.sign(np.dot(Z_val, W))\n",
    "    E_VAL = sum(preds_val != Y_val) / N_val\n",
    "\n",
    "    print(f\"E_VAL for k={k} is {E_VAL}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the smallest classification error on the validation set occurs for `k=6`, **[d]**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/val2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_OUT for k=3 is 0.42\n",
      "E_OUT for k=4 is 0.416\n",
      "E_OUT for k=5 is 0.188\n",
      "E_OUT for k=6 is 0.084\n",
      "E_OUT for k=7 is 0.072\n"
     ]
    }
   ],
   "source": [
    "test = np.loadtxt('data/hw7/out.dta.txt')\n",
    "\n",
    "X_test = test[:,:-1]\n",
    "Y_test = test[:,2]\n",
    "N_test = Y_test.shape[0]\n",
    "\n",
    "for k in range(3, 8):\n",
    "    # Non-Linear Transformation\n",
    "    Z_train = np.apply_along_axis(phi, 1, X_train, k)\n",
    "    Z_test = np.apply_along_axis(phi, 1, X_test, k)\n",
    "\n",
    "    # Linear Regression\n",
    "    X_dagger = np.dot(np.linalg.inv(np.dot(Z_train.T, Z_train)), Z_train.T)\n",
    "    W = np.dot(X_dagger, Y_train)\n",
    "\n",
    "    # Out of Sample Error\n",
    "    preds_test = np.sign(np.dot(Z_test, W))\n",
    "    E_OUT = sum(preds_test != Y_test) / N_test\n",
    "\n",
    "    print(f\"E_OUT for k={k} is {E_OUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the smalles out-of-sample error on the test set was almost predicted correctly, but not quite. The answer is **[e]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/val3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm expecting the validation set predictions to be wayyy better now, and a simpler model to \"win\" since we have less examples. Let's see :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_VAL for k=3 is 0.28\n",
      "E_VAL for k=4 is 0.36\n",
      "E_VAL for k=5 is 0.2\n",
      "E_VAL for k=6 is 0.08\n",
      "E_VAL for k=7 is 0.12\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt('data/hw7/in.dta.txt')\n",
    "\n",
    "N_train = 10\n",
    "X_train = data[-N_train:,:-1]\n",
    "Y_train = data[-N_train:,2]\n",
    "\n",
    "N_val = 25\n",
    "X_val = data[:N_val,:-1]\n",
    "Y_val = data[:N_val,2]\n",
    "\n",
    "def phi(X, k):\n",
    "    assert(X.shape == (2,))\n",
    "    x1, x2 = X\n",
    "    return np.array([1, x1, x2, x1 * x1, x2 * x2, x1 * x2, np.abs(x1-x2), np.abs(x1+x2)])[:k+1]\n",
    "\n",
    "for k in range(3, 8):\n",
    "    # Non-Linear Transformation\n",
    "    Z_train = np.apply_along_axis(phi, 1, X_train, k)\n",
    "    Z_val = np.apply_along_axis(phi, 1, X_val, k)\n",
    "\n",
    "    # Linear Regression\n",
    "    X_dagger = np.dot(np.linalg.inv(np.dot(Z_train.T, Z_train)), Z_train.T)\n",
    "    W = np.dot(X_dagger, Y_train)\n",
    "\n",
    "    # Validation Error\n",
    "    preds_val = np.sign(np.dot(Z_val, W))\n",
    "    E_VAL = sum(preds_val != Y_val) / N_val\n",
    "\n",
    "    print(f\"E_VAL for k={k} is {E_VAL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the answer is still **[d]** as above, not too much relative change here compared to 1. except that the predicted errors are much higher (as expected)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/val4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_OUT for k=3 is 0.396\n",
      "E_OUT for k=4 is 0.388\n",
      "E_OUT for k=5 is 0.284\n",
      "E_OUT for k=6 is 0.192\n",
      "E_OUT for k=7 is 0.196\n"
     ]
    }
   ],
   "source": [
    "test = np.loadtxt('data/hw7/out.dta.txt')\n",
    "\n",
    "X_test = test[:,:-1]\n",
    "Y_test = test[:,2]\n",
    "N_test = Y_test.shape[0]\n",
    "\n",
    "for k in range(3, 8):\n",
    "    # Non-Linear Transformation\n",
    "    Z_train = np.apply_along_axis(phi, 1, X_train, k)\n",
    "    Z_test = np.apply_along_axis(phi, 1, X_test, k)\n",
    "\n",
    "    # Linear Regression\n",
    "    X_dagger = np.dot(np.linalg.inv(np.dot(Z_train.T, Z_train)), Z_train.T)\n",
    "    W = np.dot(X_dagger, Y_train)\n",
    "\n",
    "    # Out of Sample Error\n",
    "    preds_test = np.sign(np.dot(Z_test, W))\n",
    "    E_OUT = sum(preds_test != Y_test) / N_test\n",
    "\n",
    "    print(f\"E_OUT for k={k} is {E_OUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And indeed the prediction is better this time! **[d]** as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/val5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the model (d) chosen in 1., we had\n",
    "\n",
    "E_OUT for k=6 is `0.084`\n",
    "\n",
    "and for the model (d) chosen in 3., we had \n",
    "\n",
    "E_OUT for k=6 is `0.192`\n",
    "\n",
    "That's closest to answer **[b]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/valbias1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stealing the result and approach from [here](https://math.stackexchange.com/questions/786392/expectation-of-minimum-of-n-i-i-d-uniform-random-variables),\n",
    "the expected value of $min(e1, e2)$ is $\\frac{1}{n+1}=\\frac{1}{3}$, hence the closest answer should be **[d]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/xvalidation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation squared error for the constant model using leave-one-out crossvalidation for answer [a] is [0.5]\n",
      "Average validation squared error for the linear model using leave-one-out crossvalidation for answer [a] is [1.13504337]\n",
      "Average validation squared error for the constant model using leave-one-out crossvalidation for answer [b] is [0.5]\n",
      "Average validation squared error for the linear model using leave-one-out crossvalidation for answer [b] is [64.66494841]\n",
      "Average validation squared error for the constant model using leave-one-out crossvalidation for answer [c] is [0.5]\n",
      "Average validation squared error for the linear model using leave-one-out crossvalidation for answer [c] is [0.5]\n",
      "Average validation squared error for the constant model using leave-one-out crossvalidation for answer [d] is [0.5]\n",
      "Average validation squared error for the linear model using leave-one-out crossvalidation for answer [d] is [0.98688393]\n"
     ]
    }
   ],
   "source": [
    "P = {\n",
    "    \"a\": np.sqrt(np.sqrt(3)+4),\n",
    "    \"b\": np.sqrt(np.sqrt(3)-1),\n",
    "    \"c\": np.sqrt(9 + 4 * np.sqrt(6)),\n",
    "    \"d\": np.sqrt(9 - np.sqrt(6))\n",
    "}\n",
    "\n",
    "# Check all 4 answers [a], [b], [c] and [d]\n",
    "for pName, p in P.items():\n",
    "    X = np.array([-1, p, 1])\n",
    "    Y = np.array([0, 1, 0])\n",
    "    N = Y.shape[0]\n",
    "\n",
    "    # Leave-one-out X-Validation\n",
    "    E_VALS_CONST = []\n",
    "    E_VALS_LIN = []\n",
    "    for i in range(N):\n",
    "        X_train = np.delete(X, i)[:, None]\n",
    "        Y_train = np.delete(Y, i)[:, None]\n",
    "        N_train = Y_train.shape[0]\n",
    "\n",
    "        X_val = X[i]\n",
    "        Y_val = Y[i]\n",
    "        N_val = 1\n",
    "\n",
    "        # Constant Model\n",
    "        b = sum(Y_train) / N_train\n",
    "        # In-sample Error\n",
    "        preds = np.repeat(b, N_train)\n",
    "        E_IN = (1/N_train) * sum(np.power(Y_train[n] - preds[n], 2) for n in range(N_train))\n",
    "        # Validation Error\n",
    "        pred_val = b\n",
    "        E_VALS_CONST.append(np.power(Y_val - pred_val, 2))\n",
    "\n",
    "        # Linear Model\n",
    "        X_train_with_const = np.c_[np.ones(N_train), X_train]\n",
    "        X_val_with_const = [1, X_val]\n",
    "        X_dagger = np.dot(np.linalg.inv(np.dot(X_train_with_const.T, X_train_with_const)), X_train_with_const.T)\n",
    "        W = np.dot(X_dagger, Y_train)\n",
    "        # In-sample Error\n",
    "        preds = np.dot(X_train_with_const, W)\n",
    "        E_IN = (1/N_train) * sum(np.power(Y_train[n] - preds[n], 2) for n in range(N_train))\n",
    "        # Validation Error\n",
    "        pred_val = np.dot(X_val_with_const, W)\n",
    "        E_VALS_LIN.append(np.power(Y_val - pred_val, 2))\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Average validation squared error for the constant model using leave-one-out crossvalidation for answer [{pName}] is {sum(E_VALS_CONST)/len(E_VALS_CONST)}\")\n",
    "    print(f\"Average validation squared error for the linear model using leave-one-out crossvalidation for answer [{pName}] is {sum(E_VALS_LIN)/len(E_VALS_LIN)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the answer is **[c]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLA vs. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/svm1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average % where g_SVM outperforms g_PLA is 0.5720000000000004\n",
      "CPU times: user 7.75 s, sys: 2.01 ms, total: 7.75 s\n",
      "Wall time: 7.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "EXPERIMENTS = 1000\n",
    "N = 10\n",
    "\n",
    "def generate_data(N):\n",
    "    # Generate a target function (see HW1 for explanations)\n",
    "    x1 = np.random.uniform(-1, 1, 2)\n",
    "    x2 = np.random.uniform(-1, 1, 2)\n",
    "    m = (x1[1] - x2[1]) / (x1[0] - x2[0])\n",
    "    c = x1[1] - m*x1[0]\n",
    "    def y(X):\n",
    "        x, y = X\n",
    "        return 1 if y > m*x+c else -1\n",
    "    \n",
    "    X = np.c_[np.random.uniform(-1, 1, N), np.random.uniform(-1, 1, N)]\n",
    "    Y = np.apply_along_axis(y, 1, X)\n",
    "    # Generate a new dataset if all points fall on the same side of the line\n",
    "    while len(set(Y)) == 1:\n",
    "        X = np.c_[np.random.uniform(-1, 1, N), np.random.uniform(-1, 1, N)]\n",
    "        Y = np.apply_along_axis(y, 1, X)\n",
    "        \n",
    "    return (X, Y, y)\n",
    "\n",
    "def generate_test_data(N, y):\n",
    "    X = np.c_[np.random.uniform(-1, 1, N), np.random.uniform(-1, 1, N)]\n",
    "    Y = np.apply_along_axis(y, 1, X)\n",
    "    \n",
    "    return (X, Y)\n",
    "\n",
    "def perceptron(N): \n",
    "    X, Y, y = generate_data(N)\n",
    "    clf = Perceptron(tol=None)\n",
    "    clf.fit(X, Y)\n",
    "    X_test, Y_test = generate_test_data(100*N, y)\n",
    "    return clf.score(X_test, Y_test)\n",
    "\n",
    "def SVM(N): \n",
    "    X, Y, y = generate_data(N)\n",
    "    clf = svm.SVC(kernel='linear', C=np.Inf, cache_size=20000)\n",
    "    clf.fit(X, Y)\n",
    "    X_test, Y_test = generate_test_data(100*N, y)\n",
    "    return clf.score(X_test, Y_test)\n",
    "\n",
    "# How often does SVM() outperform perceptron()?\n",
    "score = functools.reduce(lambda score, _: score + ((1/EXPERIMENTS) if SVM(N) > perceptron(N) else 0), range(EXPERIMENTS), 0)\n",
    "\n",
    "print(f\"Average % where g_SVM outperforms g_PLA is {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's closest to 60%, or **[c]**, so even on 10 data points, SVM outperforms PLA here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/svm2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average % where g_SVM outperforms g_PLA is 0.5680000000000004\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "\n",
    "# How often does SVM() outperform perceptron()?\n",
    "score = functools.reduce(lambda score, _: score + ((1/EXPERIMENTS) if SVM(N) > perceptron(N) else 0), range(EXPERIMENTS), 0)\n",
    "\n",
    "print(f\"Average % where g_SVM outperforms g_PLA is {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's actually closer to **[c]** than the correct answer **[d]**, so the algorithm impls must be different here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, `sklearn.svm.SVC` seems to be solving the following problem: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/sklearn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And I'm not sure how to get rid of the zeta terms..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/svm3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average # of support vectors of g_SVM is 2.998000000000002\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENTS = 1000\n",
    "N = 100\n",
    "\n",
    "def SVM(N): \n",
    "    X, Y, y = generate_data(N)\n",
    "    clf = svm.SVC(C=np.Inf, kernel='linear', cache_size=20000)\n",
    "    clf.fit(X, Y)\n",
    "    X_test, Y_test = generate_test_data(100*N, y)\n",
    "    return (clf.score(X_test, Y_test), sum(clf.n_support_))\n",
    "\n",
    "# How often does SVM() outperform perceptron()?\n",
    "score = functools.reduce(lambda score, _: score + SVM(N)[1]/EXPERIMENTS, range(EXPERIMENTS), 0)\n",
    "\n",
    "print(f\"Average # of support vectors of g_SVM is {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[b]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 - python",
   "language": "python",
   "name": "ipython_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
