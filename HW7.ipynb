{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caltech Machine Learning Homework # 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Perceptron\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "from itertools import product\n",
    "import scipy.special\n",
    "from scipy import optimize\n",
    "import scipy.optimize as spo\n",
    "from sympy import Symbol, Derivative\n",
    "import functools\n",
    "\n",
    "def dbg():\n",
    "    import pdb; pdb.set_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: https://work.caltech.edu/homework/hw7.pdf\n",
    "\n",
    "Answers: http://work.caltech.edu/homework/hw7_sol.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/val1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_VAL for k=3 is 0.3\n",
      "E_VAL for k=4 is 0.5\n",
      "E_VAL for k=5 is 0.2\n",
      "E_VAL for k=6 is 0.0\n",
      "E_VAL for k=7 is 0.1\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt('data/hw7/in.dta.txt')\n",
    "\n",
    "N_train = 25\n",
    "X_train = data[:N_train,:-1]\n",
    "Y_train = data[:N_train,2]\n",
    "\n",
    "N_val = 10\n",
    "X_val = data[-N_val:,:-1]\n",
    "Y_val = data[-N_val:,2]\n",
    "\n",
    "def phi(X, k):\n",
    "    assert(X.shape == (2,))\n",
    "    x1, x2 = X\n",
    "    return np.array([1, x1, x2, x1 * x1, x2 * x2, x1 * x2, np.abs(x1-x2), np.abs(x1+x2)])[:k+1]\n",
    "\n",
    "for k in range(3, 8):\n",
    "    # Non-Linear Transformation\n",
    "    Z_train = np.apply_along_axis(phi, 1, X_train, k)\n",
    "    Z_val = np.apply_along_axis(phi, 1, X_val, k)\n",
    "\n",
    "    # Linear Regression\n",
    "    X_dagger = np.dot(np.linalg.inv(np.dot(Z_train.T, Z_train)), Z_train.T)\n",
    "    W = np.dot(X_dagger, Y_train)\n",
    "\n",
    "    # Validation Error\n",
    "    preds_val = np.sign(np.dot(Z_val, W))\n",
    "    E_VAL = sum(preds_val != Y_val) / N_val\n",
    "\n",
    "    print(f\"E_VAL for k={k} is {E_VAL}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the smallest classification error on the validation set occurs for `k=6`, **[d]**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/val2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_OUT for k=3 is 0.42\n",
      "E_OUT for k=4 is 0.416\n",
      "E_OUT for k=5 is 0.188\n",
      "E_OUT for k=6 is 0.084\n",
      "E_OUT for k=7 is 0.072\n"
     ]
    }
   ],
   "source": [
    "test = np.loadtxt('data/hw7/out.dta.txt')\n",
    "\n",
    "X_test = test[:,:-1]\n",
    "Y_test = test[:,2]\n",
    "N_test = Y_test.shape[0]\n",
    "\n",
    "for k in range(3, 8):\n",
    "    # Non-Linear Transformation\n",
    "    Z_train = np.apply_along_axis(phi, 1, X_train, k)\n",
    "    Z_test = np.apply_along_axis(phi, 1, X_test, k)\n",
    "\n",
    "    # Linear Regression\n",
    "    X_dagger = np.dot(np.linalg.inv(np.dot(Z_train.T, Z_train)), Z_train.T)\n",
    "    W = np.dot(X_dagger, Y_train)\n",
    "\n",
    "    # Out of Sample Error\n",
    "    preds_test = np.sign(np.dot(Z_test, W))\n",
    "    E_OUT = sum(preds_test != Y_test) / N_test\n",
    "\n",
    "    print(f\"E_OUT for k={k} is {E_OUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the smalles out-of-sample error on the test set was almost predicted correctly, but not quite. The answer is **[e]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/val3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm expecting the validation set predictions to be wayyy better now, and a simpler model to \"win\" since we have less examples. Let's see :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_VAL for k=3 is 0.28\n",
      "E_VAL for k=4 is 0.36\n",
      "E_VAL for k=5 is 0.2\n",
      "E_VAL for k=6 is 0.08\n",
      "E_VAL for k=7 is 0.12\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt('data/hw7/in.dta.txt')\n",
    "\n",
    "N_train = 10\n",
    "X_train = data[-N_train:,:-1]\n",
    "Y_train = data[-N_train:,2]\n",
    "\n",
    "N_val = 25\n",
    "X_val = data[:N_val,:-1]\n",
    "Y_val = data[:N_val,2]\n",
    "\n",
    "def phi(X, k):\n",
    "    assert(X.shape == (2,))\n",
    "    x1, x2 = X\n",
    "    return np.array([1, x1, x2, x1 * x1, x2 * x2, x1 * x2, np.abs(x1-x2), np.abs(x1+x2)])[:k+1]\n",
    "\n",
    "for k in range(3, 8):\n",
    "    # Non-Linear Transformation\n",
    "    Z_train = np.apply_along_axis(phi, 1, X_train, k)\n",
    "    Z_val = np.apply_along_axis(phi, 1, X_val, k)\n",
    "\n",
    "    # Linear Regression\n",
    "    X_dagger = np.dot(np.linalg.inv(np.dot(Z_train.T, Z_train)), Z_train.T)\n",
    "    W = np.dot(X_dagger, Y_train)\n",
    "\n",
    "    # Validation Error\n",
    "    preds_val = np.sign(np.dot(Z_val, W))\n",
    "    E_VAL = sum(preds_val != Y_val) / N_val\n",
    "\n",
    "    print(f\"E_VAL for k={k} is {E_VAL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the answer is still **[d]** as above, not too much relative change here compared to 1. except that the predicted errors are much higher (as expected)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/val4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_OUT for k=3 is 0.396\n",
      "E_OUT for k=4 is 0.388\n",
      "E_OUT for k=5 is 0.284\n",
      "E_OUT for k=6 is 0.192\n",
      "E_OUT for k=7 is 0.196\n"
     ]
    }
   ],
   "source": [
    "test = np.loadtxt('data/hw7/out.dta.txt')\n",
    "\n",
    "X_test = test[:,:-1]\n",
    "Y_test = test[:,2]\n",
    "N_test = Y_test.shape[0]\n",
    "\n",
    "for k in range(3, 8):\n",
    "    # Non-Linear Transformation\n",
    "    Z_train = np.apply_along_axis(phi, 1, X_train, k)\n",
    "    Z_test = np.apply_along_axis(phi, 1, X_test, k)\n",
    "\n",
    "    # Linear Regression\n",
    "    X_dagger = np.dot(np.linalg.inv(np.dot(Z_train.T, Z_train)), Z_train.T)\n",
    "    W = np.dot(X_dagger, Y_train)\n",
    "\n",
    "    # Out of Sample Error\n",
    "    preds_test = np.sign(np.dot(Z_test, W))\n",
    "    E_OUT = sum(preds_test != Y_test) / N_test\n",
    "\n",
    "    print(f\"E_OUT for k={k} is {E_OUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And indeed the prediction is better this time! **[d]** as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/val5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the model (d) chosen in 1., we had\n",
    "\n",
    "E_OUT for k=6 is `0.084`\n",
    "\n",
    "and for the model (d) chosen in 3., we had \n",
    "\n",
    "E_OUT for k=6 is `0.192`\n",
    "\n",
    "That's closest to answer **[b]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/valbias1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stealing the result and approach from [here](https://math.stackexchange.com/questions/786392/expectation-of-minimum-of-n-i-i-d-uniform-random-variables),\n",
    "the expected value of $min(e1, e2)$ is $\\frac{1}{n+1}=\\frac{1}{3}$, hence the closest answer should be **[d]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/xvalidation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation squared error for the constant model using leave-one-out crossvalidation for answer [a] is [0.5]\n",
      "Average validation squared error for the linear model using leave-one-out crossvalidation for answer [a] is [1.13504337]\n",
      "Average validation squared error for the constant model using leave-one-out crossvalidation for answer [b] is [0.5]\n",
      "Average validation squared error for the linear model using leave-one-out crossvalidation for answer [b] is [64.66494841]\n",
      "Average validation squared error for the constant model using leave-one-out crossvalidation for answer [c] is [0.5]\n",
      "Average validation squared error for the linear model using leave-one-out crossvalidation for answer [c] is [0.5]\n",
      "Average validation squared error for the constant model using leave-one-out crossvalidation for answer [d] is [0.5]\n",
      "Average validation squared error for the linear model using leave-one-out crossvalidation for answer [d] is [0.98688393]\n"
     ]
    }
   ],
   "source": [
    "P = {\n",
    "    \"a\": np.sqrt(np.sqrt(3)+4),\n",
    "    \"b\": np.sqrt(np.sqrt(3)-1),\n",
    "    \"c\": np.sqrt(9 + 4 * np.sqrt(6)),\n",
    "    \"d\": np.sqrt(9 - np.sqrt(6))\n",
    "}\n",
    "\n",
    "# Check all 4 answers [a], [b], [c] and [d]\n",
    "for pName, p in P.items():\n",
    "    X = np.array([-1, p, 1])\n",
    "    Y = np.array([0, 1, 0])\n",
    "    N = Y.shape[0]\n",
    "\n",
    "    # Leave-one-out X-Validation\n",
    "    E_VALS_CONST = []\n",
    "    E_VALS_LIN = []\n",
    "    for i in range(N):\n",
    "        X_train = np.delete(X, i)[:, None]\n",
    "        Y_train = np.delete(Y, i)[:, None]\n",
    "        N_train = Y_train.shape[0]\n",
    "\n",
    "        X_val = X[i]\n",
    "        Y_val = Y[i]\n",
    "        N_val = 1\n",
    "\n",
    "        # Constant Model\n",
    "        b = sum(Y_train) / N_train\n",
    "        # In-sample Error\n",
    "        preds = np.repeat(b, N_train)\n",
    "        E_IN = (1/N_train) * sum(np.power(Y_train[n] - preds[n], 2) for n in range(N_train))\n",
    "        # Validation Error\n",
    "        pred_val = b\n",
    "        E_VALS_CONST.append(np.power(Y_val - pred_val, 2))\n",
    "\n",
    "        # Linear Model\n",
    "        X_train_with_const = np.c_[np.ones(N_train), X_train]\n",
    "        X_val_with_const = [1, X_val]\n",
    "        X_dagger = np.dot(np.linalg.inv(np.dot(X_train_with_const.T, X_train_with_const)), X_train_with_const.T)\n",
    "        W = np.dot(X_dagger, Y_train)\n",
    "        # In-sample Error\n",
    "        preds = np.dot(X_train_with_const, W)\n",
    "        E_IN = (1/N_train) * sum(np.power(Y_train[n] - preds[n], 2) for n in range(N_train))\n",
    "        # Validation Error\n",
    "        pred_val = np.dot(X_val_with_const, W)\n",
    "        E_VALS_LIN.append(np.power(Y_val - pred_val, 2))\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Average validation squared error for the constant model using leave-one-out crossvalidation for answer [{pName}] is {sum(E_VALS_CONST)/len(E_VALS_CONST)}\")\n",
    "    print(f\"Average validation squared error for the linear model using leave-one-out crossvalidation for answer [{pName}] is {sum(E_VALS_LIN)/len(E_VALS_LIN)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the answer is **[c]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 - python",
   "language": "python",
   "name": "ipython_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
